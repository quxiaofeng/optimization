<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Home | OPTIMIZATIONS for Machine Learning</title>
  <meta name="description" content="A little blog collecting optimization methods in machine learning field">


  <link rel="stylesheet" href="//www.quxiaofeng.me/optimization/css/tufte.css">	
  

  <!-- Google Fonts loaded here -->
  <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>

  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <link rel="canonical" href="http://www.quxiaofeng.me/optimization/">
  <link rel="alternate" type="application/rss+xml" title="OPTIMIZATIONS for Machine Learning" href="http://www.quxiaofeng.me/optimization/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
		<a href="//www.quxiaofeng.me/optimization/"><img class="badge" src="//www.quxiaofeng.me/optimization/assets/img/badge_op_ml.png" alt="OP"></a>
		<a href="//www.quxiaofeng.me/optimization/">Home</a>
		<a href="//www.quxiaofeng.me/optimization/about">About</a>
	</nav>
</header>

    <article>
        <h1 class="content-listing-header sans">Articles</h1>
  <ul class="content">
    
      <li class="listing">
      	<hr class="slender">
      	<a href="//www.quxiaofeng.me/optimization/2015/07/18/alternating-direction-method-multipliers/"><h4 class="contrast">Alternating Direction Method of Multipliers (ADMM)</h4></a>
      	<span class="smaller">July 18, 2015</span>  <br/>
		<div><h2 id="alternating-direction-method-of-multipliers-admm">Alternating Direction Method of Multipliers (ADMM)</h2>

<ul>
  <li>
    <p>Consider minimizing <script type="math/tex"> f({\bf x}) + g({\bf y}) </script> subject to affine constraints <script type="math/tex"> {\bf Ax} + {\bf By} = {\bf c} </script></p>
  </li>
  <li>
    <p>The augmented Lagrangian</p>
  </li>
</ul>

<script type="math/tex; mode=display"> \mathcal{L}_\rho({\bf x}, {\bf y}, {\bf \lambda}) = f({\bf x}) + g({\bf y}) + \langle {\bf \lambda}, {\bf Ax} + {\bf By} - {\bf c} \rangle + \frac{\rho}{2} \| {\bf Ax} + {\bf By} - {\bf c} \|^2_2 </script>

<ul>
  <li>Idea: perform block descent on <script type="math/tex">{\bf x}</script> and <script type="math/tex">{\bf y}</script> and then update multiplier vector <script type="math/tex">{\bf \lambda}</script></li>
</ul>

<script type="math/tex; mode=display">
\begin{align}
{\bf x}^{(t+1)}       & \leftarrow & \min_{\bf x} f({\bf x}) + \langle {\bf \lambda}, {\bf Ax} + {\bf By}^{(t)} - {\bf c} \rangle + \frac{\rho}{2} \| {\bf Ax} + {\bf By}^{(t)} - {\bf c} \|^2_2 \\
{\bf y}^{(t+1)}       & \leftarrow & \min_{\bf y} g({\bf y}) + \langle {\bf \lambda}, {\bf Ax}^{(t+1)} + {\bf By} - {\bf c} \rangle + \frac{\rho}{2} \| {\bf Ax}^{(t+1)} + {\bf By} - {\bf c} \|^2_2 \\
{\bf \lambda}^{(t+1)} & \leftarrow & {\bf \lambda}^{(t)} + \rho ({\bf Ax}^{(t+1)} + {\bf By}^{(t+1)} - {\bf c})
\end{align}
</script>

<h2 id="example-fused-lasso">Example: fused lasso</h2>

<p>Fused lasso problem minimizes</p>

<script type="math/tex; mode=display"> \frac{1}{2} \| {\bf y - X\beta} \|^2_2 + \mu \sum^{p-1}_{j=1} |\beta_{j+1} - \beta_j |</script>

<ul>
  <li>Define <script type="math/tex">{\bf \gamma = D\beta}</script>, where</li>
</ul>

<script type="math/tex; mode=display">
D = \left(\begin{matrix}
1 & -1 & &      &   & \\
  &    & \cdots &   & \\
  &    &        & 1 & -1 
\end{matrix}
\right)
</script>

<p>Then we minimize <script type="math/tex"> \frac{1}{2} \| {\bf y} - {\bf X\beta} \|^2_2 + \mu \| \gamma \|_1 </script> subject to <script type="math/tex"> {\bf D\beta} = \gamma </script></p>

<ul>
  <li>Augmented Lagrangian is</li>
</ul>

<script type="math/tex; mode=display">
\mathcal{L}_\rho({\bf \beta}, {\bf \gamma}, {\bf \lambda}) = \frac{1}{2} \| {\bf y} - {\bf X\beta} \|^2_2 + \mu \| {\bf \gamma} \|_1 + {\bf \lambda}^T({\bf D\beta} - {\bf \gamma}) + \frac{\rho}{2} \| {\bf D\beta} - {\bf \gamma} \|^2_2
</script>

<ul>
  <li>ADMM:
    <ul>
      <li>Update <script type="math/tex">{\bf \beta}</script> is a smooth quadratic problem</li>
      <li>Update <script type="math/tex">{\bf \gamma}</script> is a separated lasso problem (elementwise thresholding)</li>
      <li>Update multipliers</li>
    </ul>
  </li>
</ul>

<script type="math/tex; mode=display">
{\bf \lambda}^{(t+1)} \leftarrow {\bf \lambda}^{(t)} + \rho({\bf D\beta}^{(t)} - {\bf \gamma}^{(t)}) 
</script>

<ul>
  <li>Same algorithm applies to a general regularization matrix <script type="math/tex">{\bf D}</script> (generalized lasso)</li>
</ul>

<h2 id="remarks-on-admm">Remarks on ADMM</h2>

<ul>
  <li>
    <p>Related algorithms</p>

    <ul>
      <li>
        <p>split Bregman iteration <sup class="sidenote-number">1</sup><span class="sidenote"><sup class="sidenote-number">1</sup> Goldstein, T. and Osher, S. (2009). The split Bregman method for l1-regularized problems. SIAM J. Img. Sci., 2:323-343.</span></p>
      </li>
      <li>
        <p>Dykstra’s alternating projection algorithm <sup class="sidenote-number">2</sup><span class="sidenote"><sup class="sidenote-number">2</sup> Dykstra, R. L. (1983). An algorithm for restricted least squares regression. J. Amer. Statist. Assoc., 78(384):837-842.</span></p>
      </li>
      <li>
        <p>…</p>
      </li>
    </ul>
  </li>
</ul>

<p>Proximal point algorithm applied to the dual</p>

<ul>
  <li>
    <p>Numerous applications in statistics and machine learning: lasso, gen. lasso, graphical lasso, (overlapping) group lasso, …</p>
  </li>
  <li>
    <p>Embraces distributed computing for big data <sup class="sidenote-number">3</sup><span class="sidenote"><sup class="sidenote-number">3</sup> Boyd, S., Parikh, N., Chu, E., Peleato, B., and Eckstein, J. (2011). Distributed optimization and statistical learning via the alternating direction method of multipliers. Found. Trends Mach. learn., 3(1):1-122.</span></p>
  </li>
</ul>

</div>
      </li>
    
      <li class="listing">
      	<hr class="slender">
      	<a href="//www.quxiaofeng.me/optimization/2015/07/17/augmented-lagrangian-method/"><h4 class="contrast">Augmented Lagrangian Method</h4></a>
      	<span class="smaller">July 17, 2015</span>  <br/>
		<div><p>Consider minimizing <script type="math/tex"> f({\bf x}) </script> subject to equality constraints <script type="math/tex"> g_i({\bf x}) = 0 </script> for <script type="math/tex">i=1, \ldots ,q</script></p>

<ul>
  <li>
    <p>Inequality constraints are ignored for simplicity</p>
  </li>
  <li>
    <p>Assume <script type="math/tex">f</script> and <script type="math/tex">g_i</script> are smooth for simplicity</p>
  </li>
  <li>
    <p>At a constrained minimum, the Lagrange multiplier condition</p>
  </li>
</ul>

<p> <script type="math/tex; mode=display">  {\bf 0}=\nabla f({\bf x})+\sum^q_{i=1}\lambda_i\nabla g_i({\bf x})  </script> </p>

<p>holds provided <script type="math/tex">\nabla g_i({\bf x})</script> are linearly independent</p>

</div>
      </li>
    
      <li class="listing">
      	<hr class="slender">
      	<a href="//www.quxiaofeng.me/optimization/2015/07/16/introduction-to-nonlinear-optimization/"><h4 class="contrast">Introduction to Nonlinear Optimization</h4></a>
      	<span class="smaller">July 16, 2015</span>  <br/>
		<div><p>昨天晚上到今天，看完了一本之前一直看不完的书 《Introduction to Nonlinear Optimization》<sup class="sidenote-number">1</sup><span class="sidenote"><sup class="sidenote-number">1</sup> 《Introduction to Nonlinear Optimization》 at 豆瓣: <a href="http://book.douban.com/subject/26551626/">http://book.douban.com/subject/26551626/</a> and at Amazon: <a href="http://www.amazon.com/Introduction-Nonlinear-Optimization-Algorithms-Applications/dp/1611973643/">http://www.amazon.com/Introduction-Nonlinear-Optimization-Algorithms-Applications/dp/1611973643/</a></span> by Amir Beck <sup class="sidenote-number">2</sup><span class="sidenote"><sup class="sidenote-number">2</sup> Amir Beck is an associate professor at The Technion—Israel Institute of Technology： <a href="http://iew3.technion.ac.il/Home/Users/becka.html">http://iew3.technion.ac.il/Home/Users/becka.html</a></span>。澄清了一些过去曾经误解的概念。MOS-SIAM Series on Optimization<sup class="sidenote-number">3</sup><span class="sidenote"><sup class="sidenote-number">3</sup> MOS-SIAM Series on Optimization: <a href="http://bookstore.siam.org/mos-siam-series-on-optimization/">http://bookstore.siam.org/mos-siam-series-on-optimization/</a></span> 一系列优化的书都不错。连着借了三本，希望以后都能好好读完。现在这本非线性优化暂时只是翻完了，习题都没做，感觉习题也都挺有用的。</p>

</div>
      </li>
    
      <li class="listing">
      	<hr class="slender">
      	<a href="//www.quxiaofeng.me/optimization/2015/05/21/solving-sparse/"><h4 class="contrast">稀疏编码的优化问题</h4></a>
      	<span class="smaller">May 21, 2015</span>  <br/>
		<div><p>稀疏编码问题：  <script type="math/tex"> \arg\min_x f(x)\left\|y-Ax\right\|^2+ \lambda\|x\|_1 </script></p>

<ul>
  <li>用 alternating minimization (ADM)</li>
  <li>Primal-dual 算法？？</li>
  <li>Soft threshold ？？</li>
</ul>

</div>
      </li>
    
      <li class="listing">
      	<hr class="slender">
      	<a href="//www.quxiaofeng.me/optimization/2015/05/21/optimization-problems/"><h4 class="contrast">几个基本优化问题</h4></a>
      	<span class="smaller">May 21, 2015</span>  <br/>
		<div><p>可以用 ALM<sup class="sidenote-number">1</sup><span class="sidenote"><sup class="sidenote-number">1</sup> Augmented Lagrange Multiplier 增广拉格朗日乘子法</span>, LP<sup class="sidenote-number">2</sup><span class="sidenote"><sup class="sidenote-number">2</sup> Linear Programming 线性规划</span> 和 IRLS <sup class="sidenote-number">3</sup><span class="sidenote"><sup class="sidenote-number">3</sup> <a href="http://www.robotics.stanford.edu/~ang/papers/aaai06-efficientL1logisticregression.pdf">Iteratively Reweighted Least Squares</a></span> 求解的四种基本优化问题</p>

<h3 id="question-1">Question 1</h3>

<p><span class="newthought">least entropy &amp; error correction</span></p>

<p>Question 1: <script type="math/tex"> \arg \min \|x\|_1 + \|e\|_1 </script> subj. to <script type="math/tex"> y=Ax+e </script></p>

<p>标准 linear programming</p>

<p>鲁棒的 <em>SRC</em><sup class="sidenote-number">4</sup><span class="sidenote"><sup class="sidenote-number">4</sup> 参见 <a href="http://research.microsoft.com/pubs/132810/PAMI-Face.pdf">http://research.microsoft.com/pubs/132810/PAMI-Face.pdf</a> and <a href="http://perception.csl.illinois.edu/recognition/Home.html">Face Recognition via Sparse Representation</a></span>。使用单位矩阵作为遮挡字典，用标准形式求解。</p>

</div>
      </li>
    
      <li class="listing">
      	<hr class="slender">
      	<a href="//www.quxiaofeng.me/optimization/2015/02/20/tufte-style-jekyll-blog/"><h4 class="contrast">Tufte-style Jekyll blog</h4></a>
      	<span class="smaller">February 20, 2015</span>  <br/>
		<div><h2 id="introduction">Introduction</h2>

<p><span class="newthought">The Tufte Jekyll theme</span>  is an attempt to create a website design with the look and feel of Edward Tufte’s books and handouts. Tufte’s style is known for its extensive use of sidenotes, tight integration of graphics with text, and well-set typography.</p>

</div>
      </li>
    
      <li class="listing">
      	<hr class="slender">
      	<a href="//www.quxiaofeng.me/optimization/2015/02/08/welcome-to-jekyll/"><h4 class="contrast">Welcome to Jekyll!</h4></a>
      	<span class="smaller">February 8, 2015</span>  <br/>
		<div><p>You’ll find this post in your <code>_posts</code> directory - edit this post and re-build (or run with the <code>-w</code> switch) to see your changes!<br />
To add new posts, simply add a file in the <code>_posts</code> directory that follows the convention: YYYY-MM-DD-name-of-post.ext.=]</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span></code></pre></div>

<p>Check out the <a href="http://jekyllrb.com">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/mojombo/jekyll">Jekyll’s GitHub repo</a>.</p>

</div>
      </li>
    
  </ul>

    </article>
    <span class="print-footer">Home - QU Xiaofeng</span>
    <footer>
  <ul class="footer-links group">
    <li><a href="mailto:xiaofeng.qu.hk@ieee.org"><span class="icon-mail"></span></a></li>
    
      <li>
        <a href="//www.twitter.com/quxiaofeng"><span class="icon-twitter"></span></a>
      </li>
    
      <li>
        <a href="//www.facebook.com/quxiaofeng"><span class="icon-facebook"></span></a>
      </li>
    
      <li>
        <a href="//github.com/quxiaofeng"><span class="icon-github"></span></a>
      </li>
    
      <li>
        <a href="//www.quxiaofeng.me/optimization/feed"><span class="icon-feed"></span></a>
      </li>
    
  </ul>
<div class="credits">
<span>&copy; 2015 &nbsp;&nbsp;QU XIAOFENG</span></br>
<span> Themed by <a href="//github.com/clayh53/tufte-jekyll">Tufte</a> &nbsp;&nbsp; Hosted in <a href="//www.github.com">GitHub</a> &nbsp;&nbsp; Powered by <a href="//jekyllrb.com">Jekyll</a></span>
</div>
</footer>
  </body>
</html>
